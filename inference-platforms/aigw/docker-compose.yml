configs:
  # MCP servers configuration for aigw
  mcp-config:
    content: |
      {
        "mcpServers": {
          "kiwi": {
            "type": "http",
            "url": "https://mcp.kiwi.com"
          }
        }
      }

services:
  ollama-pull:
    image: alpine/ollama
    container_name: ollama-pull
    environment:
      OLLAMA_HOST: localhost:11434  # instead of IP 127.0.0.1
    env_file:
      - env.local
    entrypoint: sh
    command: -c 'env | grep _MODEL | cut -d= -f2 | xargs -I{} ollama pull {}'
    extra_hosts:  # send localhost traffic to the docker host, e.g. your laptop
      - "localhost:host-gateway"

  # aigw is the Envoy AI Gateway CLI a.k.a standalone mode.
  aigw:
    image: envoyproxy/ai-gateway-cli:latest
    container_name: aigw
    depends_on:
      ollama-pull:
        condition: service_completed_successfully
    env_file:
      - env.local
    environment:
      - OPENAI_BASE_URL=http://host.docker.internal:11434/v1
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4318
    ports:
      - "1975:1975" # OpenAI compatible endpoint at /v1, MCP server at /mcp
    configs:
      - source: mcp-config
        target: /etc/aigw/mcp-servers.json
    extra_hosts: # localhost:host-gateway trick doesn't work with aigw
      - "host.docker.internal:host-gateway"
    command: ["run", "--mcp-config", "/etc/aigw/mcp-servers.json"]
