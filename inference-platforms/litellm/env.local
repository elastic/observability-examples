# Override default ENV variables for Ollama
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_API_KEY=unused
CHAT_MODEL=qwen3:0.6B

# OpenTelemetry configuration
OTEL_SERVICE_NAME=litellm
# LiteLLM uses custom ENV until https://github.com/BerriAI/litellm/issues/9901
OTEL_EXPORTER=otlp_http
OTEL_ENDPOINT=http://localhost:4318/v1/traces

# Disable resource detectors by default
OTEL_PYTHON_DISABLED_RESOURCE_DETECTORS=all
